{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"reference/anguilla/__init__/","text":"IML Bases: JSONSerializable Source code in src/anguilla/__init__.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 class IML ( serialize . JSONSerializable ): def __init__ ( self , feature_size : Optional [ int ] = None , emb : Union [ str , embed . Embedding ] = None , interp : Union [ str , interpolate . Interpolate ] = None , index : nnsearch . Index = None , k : int = 10 , verbose = False ): \"\"\" Args: feature_size: dimension of feature vectors embed: instance or name of Feature subclass (defaults to Identity) interp: instance or name of Interpolate subclass (defaults to Smooth) index: instance of Index (defaults to IndexBrute) k: default k-nearest neighbors (can be overridden later) \"\"\" self . verbose = verbose # Feature converts Inputs to Features if emb is None : emb = embed . Identity ( feature_size ) elif isinstance ( emb , str ): emb = getattr ( embed , emb )( feature_size ) elif isinstance ( emb , embed . Embedding ): pass else : raise ValueError # Interpolate combines a set of Outputs according to their Scores if interp is None : interp = interpolate . Smooth () elif isinstance ( interp , str ): interp = getattr ( interpolate , interp )() elif isinstance ( interp , interpolate . Interpolate ): pass else : raise ValueError # Index determines the distance metric and efficiency if index is None : index = nnsearch . IndexBrute ( emb . size ) super () . __init__ ( feature_size = feature_size , emb = emb , interp = interp , index = index , k = k ) self . interpolate = interp self . embed = emb self . neighbors = nnsearch . NNSearch ( index , k = k ) self . reset () def reset ( self , keep_near : Input = None , k : int = None ): \"\"\"delete all data Args: keep_near: don't remove the neighbors of this input k: number of neighbors for above \"\"\" print ( 'reset' ) res = None if keep_near is not None and len ( self . pairs ) > 0 : if len ( keep_near ) != len ( self . pairs [ 0 ][ 0 ]): print ( 'ERROR: iml: keep_near should be an Input vector' ) keep_near = None else : print ( 'searching neighbors for keep_near' ) res = self . search ( keep_near , k = k ) self . pairs : Dict [ PairID , IOPair ] = {} # NNSearch converts feature to output IDs and scores self . neighbors . reset () if res is not None : print ( f 'restoring { len ( res . ids ) } neighbors' ) for id , inp , out in zip ( res . ids , res . inputs , res . outputs ): self . add ( inp , out , id = id ) def add ( self , input : Input , output : Output , id : Optional [ PairID ] = None ) -> PairID : \"\"\"Add a data point to the mapping. Args: input: Input item output: Output item id: PairID to use; if an existing id, replace the point Returns: id: id of the new data point if you need to reference it later \"\"\" if self . verbose : print ( f 'add { input =} , { output =} ' ) feature = self . embed ( input ) id = self . neighbors . add ( feature , id ) # track the mapping from output IDs back to outputs self . pairs [ id ] = IOPair ( input , output ) return id def get ( self , id : PairID ) -> IOPair : \"\"\"look up an Input/Output pair by ID\"\"\" try : return self . pairs [ id ] except Exception : print ( \"NNSearch: WARNING: can't `get` ID which doesn't exist or has been removed\" ) def remove ( self , ids : Union [ PairID , PairIDs ]): \"\"\"Remove from mapping by ID(s) \"\"\" # iterable of ids case: if hasattr ( ids , '__len__' ): for id in ids : self . remove ( id ) # single id case: else : try : del self . pairs [ ids ] except Exception : print ( f \"IML: WARNING: can't `remove` ID { ids } which doesn't exist or has already been removed\" ) self . neighbors . remove ( ids ) def remove_near ( self , input : Input , k : int = None ): \"\"\"Remove from mapping by proximity to Input \"\"\" feature = self . embed ( input ) self . neighbors . remove_near ( feature ) def search ( self , input : Input , k : int = None ) -> SearchResult : \"\"\"find k-nearest neighbors Args: input: input item k: max number of neighbors Returns: inputs: neighboring Inputs outputs: corresponding Outputs ids: ids of Input/Output pairs scores: dissimilarity Scores \"\"\" feature = self . embed ( input ) ids , scores = self . neighbors ( feature , k = k ) # handle case where there are fewer than k neighbors if not len ( ids ): raise RuntimeError ( 'no points in mapping. add some!' ) inputs , outputs = zip ( * ( self . pairs [ i ] for i in ids )) # TODO: text-mode visualize scores # s = ' '*len(self.pairs) return SearchResult ( inputs , outputs , ids , scores ) def map ( self , input : Input , k : int = None , ** kw ) -> Output : \"\"\"convert an Input to an Output using search + interpolate Args: input: input k: max neighbors **kw: additional arguments are passed to interpolate Returns: output instance \"\"\" # print(f'map {input=}') _ , outputs , _ , scores = self . search ( input , k ) result = self . interpolate ( outputs , scores , ** kw ) return result def save_state ( self ): \"\"\"return dataset from this IML object. Returns: state: data in this IML object \"\"\" return { 'pairs' : self . pairs } def load_state ( self , state ): \"\"\"load dataset into this IML object. Args: state: data as obtained from `save_state` \"\"\" for id , pair in state [ 'pairs' ] . items (): self . add ( * pair , id = PairID ( id )) def save ( self , path : str ): \"\"\"serialize the whole IML object to JSON Args: path: path to JSON file \"\"\" serialize . save ( path , self ) @classmethod def load ( cls , path ): \"\"\"deserialize a new IML object from JSON Args: path: path to JSON file Returns: new IML instance \"\"\" inst = serialize . load ( path ) assert isinstance ( inst , cls ), type ( inst ) return inst __init__ ( feature_size = None , emb = None , interp = None , index = None , k = 10 , verbose = False ) Parameters: Name Type Description Default feature_size Optional [ int ] dimension of feature vectors None embed instance or name of Feature subclass (defaults to Identity) required interp Union [ str , Interpolate ] instance or name of Interpolate subclass (defaults to Smooth) None index Index instance of Index (defaults to IndexBrute) None k int default k-nearest neighbors (can be overridden later) 10 Source code in src/anguilla/__init__.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def __init__ ( self , feature_size : Optional [ int ] = None , emb : Union [ str , embed . Embedding ] = None , interp : Union [ str , interpolate . Interpolate ] = None , index : nnsearch . Index = None , k : int = 10 , verbose = False ): \"\"\" Args: feature_size: dimension of feature vectors embed: instance or name of Feature subclass (defaults to Identity) interp: instance or name of Interpolate subclass (defaults to Smooth) index: instance of Index (defaults to IndexBrute) k: default k-nearest neighbors (can be overridden later) \"\"\" self . verbose = verbose # Feature converts Inputs to Features if emb is None : emb = embed . Identity ( feature_size ) elif isinstance ( emb , str ): emb = getattr ( embed , emb )( feature_size ) elif isinstance ( emb , embed . Embedding ): pass else : raise ValueError # Interpolate combines a set of Outputs according to their Scores if interp is None : interp = interpolate . Smooth () elif isinstance ( interp , str ): interp = getattr ( interpolate , interp )() elif isinstance ( interp , interpolate . Interpolate ): pass else : raise ValueError # Index determines the distance metric and efficiency if index is None : index = nnsearch . IndexBrute ( emb . size ) super () . __init__ ( feature_size = feature_size , emb = emb , interp = interp , index = index , k = k ) self . interpolate = interp self . embed = emb self . neighbors = nnsearch . NNSearch ( index , k = k ) self . reset () add ( input , output , id = None ) Add a data point to the mapping. Args: input: Input item output: Output item id: PairID to use; if an existing id, replace the point Returns: id: id of the new data point if you need to reference it later Source code in src/anguilla/__init__.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 def add ( self , input : Input , output : Output , id : Optional [ PairID ] = None ) -> PairID : \"\"\"Add a data point to the mapping. Args: input: Input item output: Output item id: PairID to use; if an existing id, replace the point Returns: id: id of the new data point if you need to reference it later \"\"\" if self . verbose : print ( f 'add { input =} , { output =} ' ) feature = self . embed ( input ) id = self . neighbors . add ( feature , id ) # track the mapping from output IDs back to outputs self . pairs [ id ] = IOPair ( input , output ) return id get ( id ) look up an Input/Output pair by ID Source code in src/anguilla/__init__.py 107 108 109 110 111 112 def get ( self , id : PairID ) -> IOPair : \"\"\"look up an Input/Output pair by ID\"\"\" try : return self . pairs [ id ] except Exception : print ( \"NNSearch: WARNING: can't `get` ID which doesn't exist or has been removed\" ) load ( path ) classmethod deserialize a new IML object from JSON Args: path: path to JSON file Returns: new IML instance Source code in src/anguilla/__init__.py 198 199 200 201 202 203 204 205 206 207 208 @classmethod def load ( cls , path ): \"\"\"deserialize a new IML object from JSON Args: path: path to JSON file Returns: new IML instance \"\"\" inst = serialize . load ( path ) assert isinstance ( inst , cls ), type ( inst ) return inst load_state ( state ) load dataset into this IML object. Args: state: data as obtained from save_state Source code in src/anguilla/__init__.py 183 184 185 186 187 188 189 def load_state ( self , state ): \"\"\"load dataset into this IML object. Args: state: data as obtained from `save_state` \"\"\" for id , pair in state [ 'pairs' ] . items (): self . add ( * pair , id = PairID ( id )) map ( input , k = None , ** kw ) convert an Input to an Output using search + interpolate Parameters: Name Type Description Default input Input input required k int max neighbors None **kw additional arguments are passed to interpolate {} Returns: output instance Source code in src/anguilla/__init__.py 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 def map ( self , input : Input , k : int = None , ** kw ) -> Output : \"\"\"convert an Input to an Output using search + interpolate Args: input: input k: max neighbors **kw: additional arguments are passed to interpolate Returns: output instance \"\"\" # print(f'map {input=}') _ , outputs , _ , scores = self . search ( input , k ) result = self . interpolate ( outputs , scores , ** kw ) return result remove ( ids ) Remove from mapping by ID(s) Source code in src/anguilla/__init__.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 def remove ( self , ids : Union [ PairID , PairIDs ]): \"\"\"Remove from mapping by ID(s) \"\"\" # iterable of ids case: if hasattr ( ids , '__len__' ): for id in ids : self . remove ( id ) # single id case: else : try : del self . pairs [ ids ] except Exception : print ( f \"IML: WARNING: can't `remove` ID { ids } which doesn't exist or has already been removed\" ) self . neighbors . remove ( ids ) remove_near ( input , k = None ) Remove from mapping by proximity to Input Source code in src/anguilla/__init__.py 129 130 131 132 133 def remove_near ( self , input : Input , k : int = None ): \"\"\"Remove from mapping by proximity to Input \"\"\" feature = self . embed ( input ) self . neighbors . remove_near ( feature ) reset ( keep_near = None , k = None ) delete all data Args: keep_near: don't remove the neighbors of this input k: number of neighbors for above Source code in src/anguilla/__init__.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 def reset ( self , keep_near : Input = None , k : int = None ): \"\"\"delete all data Args: keep_near: don't remove the neighbors of this input k: number of neighbors for above \"\"\" print ( 'reset' ) res = None if keep_near is not None and len ( self . pairs ) > 0 : if len ( keep_near ) != len ( self . pairs [ 0 ][ 0 ]): print ( 'ERROR: iml: keep_near should be an Input vector' ) keep_near = None else : print ( 'searching neighbors for keep_near' ) res = self . search ( keep_near , k = k ) self . pairs : Dict [ PairID , IOPair ] = {} # NNSearch converts feature to output IDs and scores self . neighbors . reset () if res is not None : print ( f 'restoring { len ( res . ids ) } neighbors' ) for id , inp , out in zip ( res . ids , res . inputs , res . outputs ): self . add ( inp , out , id = id ) save ( path ) serialize the whole IML object to JSON Args: path: path to JSON file Source code in src/anguilla/__init__.py 191 192 193 194 195 196 def save ( self , path : str ): \"\"\"serialize the whole IML object to JSON Args: path: path to JSON file \"\"\" serialize . save ( path , self ) save_state () return dataset from this IML object. Returns: state: data in this IML object Source code in src/anguilla/__init__.py 174 175 176 177 178 179 180 181 def save_state ( self ): \"\"\"return dataset from this IML object. Returns: state: data in this IML object \"\"\" return { 'pairs' : self . pairs } search ( input , k = None ) find k-nearest neighbors Args: input: input item k: max number of neighbors Returns: inputs: neighboring Inputs outputs: corresponding Outputs ids: ids of Input/Output pairs scores: dissimilarity Scores Source code in src/anguilla/__init__.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 def search ( self , input : Input , k : int = None ) -> SearchResult : \"\"\"find k-nearest neighbors Args: input: input item k: max number of neighbors Returns: inputs: neighboring Inputs outputs: corresponding Outputs ids: ids of Input/Output pairs scores: dissimilarity Scores \"\"\" feature = self . embed ( input ) ids , scores = self . neighbors ( feature , k = k ) # handle case where there are fewer than k neighbors if not len ( ids ): raise RuntimeError ( 'no points in mapping. add some!' ) inputs , outputs = zip ( * ( self . pairs [ i ] for i in ids )) # TODO: text-mode visualize scores # s = ' '*len(self.pairs) return SearchResult ( inputs , outputs , ids , scores )","title":"  init  "},{"location":"reference/anguilla/__init__/#anguilla.IML","text":"Bases: JSONSerializable Source code in src/anguilla/__init__.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 class IML ( serialize . JSONSerializable ): def __init__ ( self , feature_size : Optional [ int ] = None , emb : Union [ str , embed . Embedding ] = None , interp : Union [ str , interpolate . Interpolate ] = None , index : nnsearch . Index = None , k : int = 10 , verbose = False ): \"\"\" Args: feature_size: dimension of feature vectors embed: instance or name of Feature subclass (defaults to Identity) interp: instance or name of Interpolate subclass (defaults to Smooth) index: instance of Index (defaults to IndexBrute) k: default k-nearest neighbors (can be overridden later) \"\"\" self . verbose = verbose # Feature converts Inputs to Features if emb is None : emb = embed . Identity ( feature_size ) elif isinstance ( emb , str ): emb = getattr ( embed , emb )( feature_size ) elif isinstance ( emb , embed . Embedding ): pass else : raise ValueError # Interpolate combines a set of Outputs according to their Scores if interp is None : interp = interpolate . Smooth () elif isinstance ( interp , str ): interp = getattr ( interpolate , interp )() elif isinstance ( interp , interpolate . Interpolate ): pass else : raise ValueError # Index determines the distance metric and efficiency if index is None : index = nnsearch . IndexBrute ( emb . size ) super () . __init__ ( feature_size = feature_size , emb = emb , interp = interp , index = index , k = k ) self . interpolate = interp self . embed = emb self . neighbors = nnsearch . NNSearch ( index , k = k ) self . reset () def reset ( self , keep_near : Input = None , k : int = None ): \"\"\"delete all data Args: keep_near: don't remove the neighbors of this input k: number of neighbors for above \"\"\" print ( 'reset' ) res = None if keep_near is not None and len ( self . pairs ) > 0 : if len ( keep_near ) != len ( self . pairs [ 0 ][ 0 ]): print ( 'ERROR: iml: keep_near should be an Input vector' ) keep_near = None else : print ( 'searching neighbors for keep_near' ) res = self . search ( keep_near , k = k ) self . pairs : Dict [ PairID , IOPair ] = {} # NNSearch converts feature to output IDs and scores self . neighbors . reset () if res is not None : print ( f 'restoring { len ( res . ids ) } neighbors' ) for id , inp , out in zip ( res . ids , res . inputs , res . outputs ): self . add ( inp , out , id = id ) def add ( self , input : Input , output : Output , id : Optional [ PairID ] = None ) -> PairID : \"\"\"Add a data point to the mapping. Args: input: Input item output: Output item id: PairID to use; if an existing id, replace the point Returns: id: id of the new data point if you need to reference it later \"\"\" if self . verbose : print ( f 'add { input =} , { output =} ' ) feature = self . embed ( input ) id = self . neighbors . add ( feature , id ) # track the mapping from output IDs back to outputs self . pairs [ id ] = IOPair ( input , output ) return id def get ( self , id : PairID ) -> IOPair : \"\"\"look up an Input/Output pair by ID\"\"\" try : return self . pairs [ id ] except Exception : print ( \"NNSearch: WARNING: can't `get` ID which doesn't exist or has been removed\" ) def remove ( self , ids : Union [ PairID , PairIDs ]): \"\"\"Remove from mapping by ID(s) \"\"\" # iterable of ids case: if hasattr ( ids , '__len__' ): for id in ids : self . remove ( id ) # single id case: else : try : del self . pairs [ ids ] except Exception : print ( f \"IML: WARNING: can't `remove` ID { ids } which doesn't exist or has already been removed\" ) self . neighbors . remove ( ids ) def remove_near ( self , input : Input , k : int = None ): \"\"\"Remove from mapping by proximity to Input \"\"\" feature = self . embed ( input ) self . neighbors . remove_near ( feature ) def search ( self , input : Input , k : int = None ) -> SearchResult : \"\"\"find k-nearest neighbors Args: input: input item k: max number of neighbors Returns: inputs: neighboring Inputs outputs: corresponding Outputs ids: ids of Input/Output pairs scores: dissimilarity Scores \"\"\" feature = self . embed ( input ) ids , scores = self . neighbors ( feature , k = k ) # handle case where there are fewer than k neighbors if not len ( ids ): raise RuntimeError ( 'no points in mapping. add some!' ) inputs , outputs = zip ( * ( self . pairs [ i ] for i in ids )) # TODO: text-mode visualize scores # s = ' '*len(self.pairs) return SearchResult ( inputs , outputs , ids , scores ) def map ( self , input : Input , k : int = None , ** kw ) -> Output : \"\"\"convert an Input to an Output using search + interpolate Args: input: input k: max neighbors **kw: additional arguments are passed to interpolate Returns: output instance \"\"\" # print(f'map {input=}') _ , outputs , _ , scores = self . search ( input , k ) result = self . interpolate ( outputs , scores , ** kw ) return result def save_state ( self ): \"\"\"return dataset from this IML object. Returns: state: data in this IML object \"\"\" return { 'pairs' : self . pairs } def load_state ( self , state ): \"\"\"load dataset into this IML object. Args: state: data as obtained from `save_state` \"\"\" for id , pair in state [ 'pairs' ] . items (): self . add ( * pair , id = PairID ( id )) def save ( self , path : str ): \"\"\"serialize the whole IML object to JSON Args: path: path to JSON file \"\"\" serialize . save ( path , self ) @classmethod def load ( cls , path ): \"\"\"deserialize a new IML object from JSON Args: path: path to JSON file Returns: new IML instance \"\"\" inst = serialize . load ( path ) assert isinstance ( inst , cls ), type ( inst ) return inst","title":"IML"},{"location":"reference/anguilla/__init__/#anguilla.IML.__init__","text":"Parameters: Name Type Description Default feature_size Optional [ int ] dimension of feature vectors None embed instance or name of Feature subclass (defaults to Identity) required interp Union [ str , Interpolate ] instance or name of Interpolate subclass (defaults to Smooth) None index Index instance of Index (defaults to IndexBrute) None k int default k-nearest neighbors (can be overridden later) 10 Source code in src/anguilla/__init__.py 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def __init__ ( self , feature_size : Optional [ int ] = None , emb : Union [ str , embed . Embedding ] = None , interp : Union [ str , interpolate . Interpolate ] = None , index : nnsearch . Index = None , k : int = 10 , verbose = False ): \"\"\" Args: feature_size: dimension of feature vectors embed: instance or name of Feature subclass (defaults to Identity) interp: instance or name of Interpolate subclass (defaults to Smooth) index: instance of Index (defaults to IndexBrute) k: default k-nearest neighbors (can be overridden later) \"\"\" self . verbose = verbose # Feature converts Inputs to Features if emb is None : emb = embed . Identity ( feature_size ) elif isinstance ( emb , str ): emb = getattr ( embed , emb )( feature_size ) elif isinstance ( emb , embed . Embedding ): pass else : raise ValueError # Interpolate combines a set of Outputs according to their Scores if interp is None : interp = interpolate . Smooth () elif isinstance ( interp , str ): interp = getattr ( interpolate , interp )() elif isinstance ( interp , interpolate . Interpolate ): pass else : raise ValueError # Index determines the distance metric and efficiency if index is None : index = nnsearch . IndexBrute ( emb . size ) super () . __init__ ( feature_size = feature_size , emb = emb , interp = interp , index = index , k = k ) self . interpolate = interp self . embed = emb self . neighbors = nnsearch . NNSearch ( index , k = k ) self . reset ()","title":"__init__()"},{"location":"reference/anguilla/__init__/#anguilla.IML.add","text":"Add a data point to the mapping. Args: input: Input item output: Output item id: PairID to use; if an existing id, replace the point Returns: id: id of the new data point if you need to reference it later Source code in src/anguilla/__init__.py 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 def add ( self , input : Input , output : Output , id : Optional [ PairID ] = None ) -> PairID : \"\"\"Add a data point to the mapping. Args: input: Input item output: Output item id: PairID to use; if an existing id, replace the point Returns: id: id of the new data point if you need to reference it later \"\"\" if self . verbose : print ( f 'add { input =} , { output =} ' ) feature = self . embed ( input ) id = self . neighbors . add ( feature , id ) # track the mapping from output IDs back to outputs self . pairs [ id ] = IOPair ( input , output ) return id","title":"add()"},{"location":"reference/anguilla/__init__/#anguilla.IML.get","text":"look up an Input/Output pair by ID Source code in src/anguilla/__init__.py 107 108 109 110 111 112 def get ( self , id : PairID ) -> IOPair : \"\"\"look up an Input/Output pair by ID\"\"\" try : return self . pairs [ id ] except Exception : print ( \"NNSearch: WARNING: can't `get` ID which doesn't exist or has been removed\" )","title":"get()"},{"location":"reference/anguilla/__init__/#anguilla.IML.load","text":"deserialize a new IML object from JSON Args: path: path to JSON file Returns: new IML instance Source code in src/anguilla/__init__.py 198 199 200 201 202 203 204 205 206 207 208 @classmethod def load ( cls , path ): \"\"\"deserialize a new IML object from JSON Args: path: path to JSON file Returns: new IML instance \"\"\" inst = serialize . load ( path ) assert isinstance ( inst , cls ), type ( inst ) return inst","title":"load()"},{"location":"reference/anguilla/__init__/#anguilla.IML.load_state","text":"load dataset into this IML object. Args: state: data as obtained from save_state Source code in src/anguilla/__init__.py 183 184 185 186 187 188 189 def load_state ( self , state ): \"\"\"load dataset into this IML object. Args: state: data as obtained from `save_state` \"\"\" for id , pair in state [ 'pairs' ] . items (): self . add ( * pair , id = PairID ( id ))","title":"load_state()"},{"location":"reference/anguilla/__init__/#anguilla.IML.map","text":"convert an Input to an Output using search + interpolate Parameters: Name Type Description Default input Input input required k int max neighbors None **kw additional arguments are passed to interpolate {} Returns: output instance Source code in src/anguilla/__init__.py 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 def map ( self , input : Input , k : int = None , ** kw ) -> Output : \"\"\"convert an Input to an Output using search + interpolate Args: input: input k: max neighbors **kw: additional arguments are passed to interpolate Returns: output instance \"\"\" # print(f'map {input=}') _ , outputs , _ , scores = self . search ( input , k ) result = self . interpolate ( outputs , scores , ** kw ) return result","title":"map()"},{"location":"reference/anguilla/__init__/#anguilla.IML.remove","text":"Remove from mapping by ID(s) Source code in src/anguilla/__init__.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 def remove ( self , ids : Union [ PairID , PairIDs ]): \"\"\"Remove from mapping by ID(s) \"\"\" # iterable of ids case: if hasattr ( ids , '__len__' ): for id in ids : self . remove ( id ) # single id case: else : try : del self . pairs [ ids ] except Exception : print ( f \"IML: WARNING: can't `remove` ID { ids } which doesn't exist or has already been removed\" ) self . neighbors . remove ( ids )","title":"remove()"},{"location":"reference/anguilla/__init__/#anguilla.IML.remove_near","text":"Remove from mapping by proximity to Input Source code in src/anguilla/__init__.py 129 130 131 132 133 def remove_near ( self , input : Input , k : int = None ): \"\"\"Remove from mapping by proximity to Input \"\"\" feature = self . embed ( input ) self . neighbors . remove_near ( feature )","title":"remove_near()"},{"location":"reference/anguilla/__init__/#anguilla.IML.reset","text":"delete all data Args: keep_near: don't remove the neighbors of this input k: number of neighbors for above Source code in src/anguilla/__init__.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 def reset ( self , keep_near : Input = None , k : int = None ): \"\"\"delete all data Args: keep_near: don't remove the neighbors of this input k: number of neighbors for above \"\"\" print ( 'reset' ) res = None if keep_near is not None and len ( self . pairs ) > 0 : if len ( keep_near ) != len ( self . pairs [ 0 ][ 0 ]): print ( 'ERROR: iml: keep_near should be an Input vector' ) keep_near = None else : print ( 'searching neighbors for keep_near' ) res = self . search ( keep_near , k = k ) self . pairs : Dict [ PairID , IOPair ] = {} # NNSearch converts feature to output IDs and scores self . neighbors . reset () if res is not None : print ( f 'restoring { len ( res . ids ) } neighbors' ) for id , inp , out in zip ( res . ids , res . inputs , res . outputs ): self . add ( inp , out , id = id )","title":"reset()"},{"location":"reference/anguilla/__init__/#anguilla.IML.save","text":"serialize the whole IML object to JSON Args: path: path to JSON file Source code in src/anguilla/__init__.py 191 192 193 194 195 196 def save ( self , path : str ): \"\"\"serialize the whole IML object to JSON Args: path: path to JSON file \"\"\" serialize . save ( path , self )","title":"save()"},{"location":"reference/anguilla/__init__/#anguilla.IML.save_state","text":"return dataset from this IML object. Returns: state: data in this IML object Source code in src/anguilla/__init__.py 174 175 176 177 178 179 180 181 def save_state ( self ): \"\"\"return dataset from this IML object. Returns: state: data in this IML object \"\"\" return { 'pairs' : self . pairs }","title":"save_state()"},{"location":"reference/anguilla/__init__/#anguilla.IML.search","text":"find k-nearest neighbors Args: input: input item k: max number of neighbors Returns: inputs: neighboring Inputs outputs: corresponding Outputs ids: ids of Input/Output pairs scores: dissimilarity Scores Source code in src/anguilla/__init__.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 def search ( self , input : Input , k : int = None ) -> SearchResult : \"\"\"find k-nearest neighbors Args: input: input item k: max number of neighbors Returns: inputs: neighboring Inputs outputs: corresponding Outputs ids: ids of Input/Output pairs scores: dissimilarity Scores \"\"\" feature = self . embed ( input ) ids , scores = self . neighbors ( feature , k = k ) # handle case where there are fewer than k neighbors if not len ( ids ): raise RuntimeError ( 'no points in mapping. add some!' ) inputs , outputs = zip ( * ( self . pairs [ i ] for i in ids )) # TODO: text-mode visualize scores # s = ' '*len(self.pairs) return SearchResult ( inputs , outputs , ids , scores )","title":"search()"},{"location":"reference/anguilla/embed/","text":"Identity Bases: Embedding For fixed-length vector data: just check size and convert to numpy array Source code in src/anguilla/embed.py 13 14 15 16 17 18 19 20 21 22 23 24 class Identity ( Embedding ): \"\"\"For fixed-length vector data: just check size and convert to numpy array\"\"\" def __init__ ( self , size ): \"\"\"size is both the Input and Feature size\"\"\" super () . __init__ ( size = size ) self . size = self . input_size = size def __call__ ( self , source ): source , = np_coerce ( source ) if self . size is not None : assert source . shape [ - 1 ] == self . size , ( source . shape , self . size ) return source __init__ ( size ) size is both the Input and Feature size Source code in src/anguilla/embed.py 15 16 17 18 def __init__ ( self , size ): \"\"\"size is both the Input and Feature size\"\"\" super () . __init__ ( size = size ) self . size = self . input_size = size ProjectAndSort Bases: Embedding for point cloud-like data. use with L2 distance to compute sliced optimal transport. if an Input is a 2D array [B x C], B being the batch dimension (order not meaningful) and C being the coordinate dimension (order meaningful) e.g. [ [x0,y0,z0], [x1,y1,z1], [x2,y2,z2], [x3,y3,z3], ] would be a cloud of B=4 points in C=3 dimensional space This computes n pseudo-random projections down to 1-dimensional spaces, sorts along those lines, and then concatenates to make one feature vector. the L2 distance between feature vectors is the sliced OT distance between point clouds. Source code in src/anguilla/embed.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 class ProjectAndSort ( Embedding ): \"\"\" for point cloud-like data. use with L2 distance to compute sliced optimal transport. if an Input is a 2D array [B x C], B being the batch dimension (order not meaningful) and C being the coordinate dimension (order meaningful) e.g. [ [x0,y0,z0], [x1,y1,z1], [x2,y2,z2], [x3,y3,z3], ] would be a cloud of B=4 points in C=3 dimensional space This computes `n` pseudo-random projections down to 1-dimensional spaces, sorts along those lines, and then concatenates to make one feature vector. the L2 distance between feature vectors is the sliced OT distance between point clouds. \"\"\" def __init__ ( self , input_size : Tuple [ int , int ] = None , n : int = 16 ): \"\"\" Args: input_size: input shape [B,C]; if None, lazy init on first __call__ n: number of random projections. \"\"\" super () . __init__ ( input_size = input_size , n = n ) assert len ( input_size ) == 2 , \"ProjectAndSort expects fixed-size 2D array data\" self . n = n if input_size is not None : self . init ( input_size ) else : self . input_size = None def init ( self , input_size ): self . input_size = tuple ( input_size ) self . size = input_size [ 0 ] * self . n proj = np . random . randn ( input_size [ 1 ], self . n ) proj = proj / np . linalg . norm ( proj , axis = 0 , keepdims = True ) self . proj = proj def __call__ ( self , source ): source , = np_coerce ( source ) if self . input_size is None : # lazy init self . init ( source . shape [ - 2 :]) else : assert source . shape [ - 2 :] == self . input_size , ( source . shape , self . input_size ) # project coordinate dimension to n lines feat = source @ self . proj # sort along the lines feat = np . sort ( feat , axis =- 2 ) # flatten # feat = feat.T feat = feat . reshape (( * feat . shape [: - 2 ], - 1 )) return feat / np . sqrt ( self . size ) __init__ ( input_size = None , n = 16 ) Parameters: Name Type Description Default input_size Tuple [ int , int ] input shape [B,C]; if None, lazy init on first call None n int number of random projections. 16 Source code in src/anguilla/embed.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def __init__ ( self , input_size : Tuple [ int , int ] = None , n : int = 16 ): \"\"\" Args: input_size: input shape [B,C]; if None, lazy init on first __call__ n: number of random projections. \"\"\" super () . __init__ ( input_size = input_size , n = n ) assert len ( input_size ) == 2 , \"ProjectAndSort expects fixed-size 2D array data\" self . n = n if input_size is not None : self . init ( input_size ) else : self . input_size = None","title":"Embed"},{"location":"reference/anguilla/embed/#anguilla.embed.Identity","text":"Bases: Embedding For fixed-length vector data: just check size and convert to numpy array Source code in src/anguilla/embed.py 13 14 15 16 17 18 19 20 21 22 23 24 class Identity ( Embedding ): \"\"\"For fixed-length vector data: just check size and convert to numpy array\"\"\" def __init__ ( self , size ): \"\"\"size is both the Input and Feature size\"\"\" super () . __init__ ( size = size ) self . size = self . input_size = size def __call__ ( self , source ): source , = np_coerce ( source ) if self . size is not None : assert source . shape [ - 1 ] == self . size , ( source . shape , self . size ) return source","title":"Identity"},{"location":"reference/anguilla/embed/#anguilla.embed.Identity.__init__","text":"size is both the Input and Feature size Source code in src/anguilla/embed.py 15 16 17 18 def __init__ ( self , size ): \"\"\"size is both the Input and Feature size\"\"\" super () . __init__ ( size = size ) self . size = self . input_size = size","title":"__init__()"},{"location":"reference/anguilla/embed/#anguilla.embed.ProjectAndSort","text":"Bases: Embedding for point cloud-like data. use with L2 distance to compute sliced optimal transport. if an Input is a 2D array [B x C], B being the batch dimension (order not meaningful) and C being the coordinate dimension (order meaningful) e.g. [ [x0,y0,z0], [x1,y1,z1], [x2,y2,z2], [x3,y3,z3], ] would be a cloud of B=4 points in C=3 dimensional space This computes n pseudo-random projections down to 1-dimensional spaces, sorts along those lines, and then concatenates to make one feature vector. the L2 distance between feature vectors is the sliced OT distance between point clouds. Source code in src/anguilla/embed.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 class ProjectAndSort ( Embedding ): \"\"\" for point cloud-like data. use with L2 distance to compute sliced optimal transport. if an Input is a 2D array [B x C], B being the batch dimension (order not meaningful) and C being the coordinate dimension (order meaningful) e.g. [ [x0,y0,z0], [x1,y1,z1], [x2,y2,z2], [x3,y3,z3], ] would be a cloud of B=4 points in C=3 dimensional space This computes `n` pseudo-random projections down to 1-dimensional spaces, sorts along those lines, and then concatenates to make one feature vector. the L2 distance between feature vectors is the sliced OT distance between point clouds. \"\"\" def __init__ ( self , input_size : Tuple [ int , int ] = None , n : int = 16 ): \"\"\" Args: input_size: input shape [B,C]; if None, lazy init on first __call__ n: number of random projections. \"\"\" super () . __init__ ( input_size = input_size , n = n ) assert len ( input_size ) == 2 , \"ProjectAndSort expects fixed-size 2D array data\" self . n = n if input_size is not None : self . init ( input_size ) else : self . input_size = None def init ( self , input_size ): self . input_size = tuple ( input_size ) self . size = input_size [ 0 ] * self . n proj = np . random . randn ( input_size [ 1 ], self . n ) proj = proj / np . linalg . norm ( proj , axis = 0 , keepdims = True ) self . proj = proj def __call__ ( self , source ): source , = np_coerce ( source ) if self . input_size is None : # lazy init self . init ( source . shape [ - 2 :]) else : assert source . shape [ - 2 :] == self . input_size , ( source . shape , self . input_size ) # project coordinate dimension to n lines feat = source @ self . proj # sort along the lines feat = np . sort ( feat , axis =- 2 ) # flatten # feat = feat.T feat = feat . reshape (( * feat . shape [: - 2 ], - 1 )) return feat / np . sqrt ( self . size )","title":"ProjectAndSort"},{"location":"reference/anguilla/embed/#anguilla.embed.ProjectAndSort.__init__","text":"Parameters: Name Type Description Default input_size Tuple [ int , int ] input shape [B,C]; if None, lazy init on first call None n int number of random projections. 16 Source code in src/anguilla/embed.py 49 50 51 52 53 54 55 56 57 58 59 60 61 62 def __init__ ( self , input_size : Tuple [ int , int ] = None , n : int = 16 ): \"\"\" Args: input_size: input shape [B,C]; if None, lazy init on first __call__ n: number of random projections. \"\"\" super () . __init__ ( input_size = input_size , n = n ) assert len ( input_size ) == 2 , \"ProjectAndSort expects fixed-size 2D array data\" self . n = n if input_size is not None : self . init ( input_size ) else : self . input_size = None","title":"__init__()"},{"location":"reference/anguilla/interpolate/","text":"Interpolate Bases: JSONSerializable Interpolate combines a set of Outputs weighted by similarity scores. Source code in src/anguilla/interpolate.py 6 7 8 9 10 11 12 13 14 class Interpolate ( JSONSerializable ): \"\"\" Interpolate combines a set of Outputs weighted by similarity scores. \"\"\" def __init__ ( self , ** kw ): super () . __init__ ( ** kw ) def __call__ ( self , targets : List [ Output ], scores : Scores ) -> Output : raise NotImplementedError Mean Bases: Interpolate mean of neighbors (piecewise constant mapping) Source code in src/anguilla/interpolate.py 16 17 18 19 20 21 22 class Mean ( Interpolate ): \"\"\"mean of neighbors (piecewise constant mapping)\"\"\" def __init__ ( self ): super () . __init__ () def __call__ ( self , targets , scores ): return sum ( targets ) / len ( targets ) Ripple Bases: Interpolate like Smooth but with high-frequency ripples outside the input domain. works well for making random mappings in high dimensional spaces / bootstrapping expressive mappings from a few points. Source code in src/anguilla/interpolate.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 class Ripple ( Interpolate ): \"\"\"like Smooth but with high-frequency ripples outside the input domain. works well for making random mappings in high dimensional spaces / bootstrapping expressive mappings from a few points. \"\"\" def __init__ ( self ): super () . __init__ () def __call__ ( self , targets , scores , ripple = 1 , ripple_depth = 1 , eps = 1e-9 ): targets , scores = np_coerce ( targets , scores ) scores = scores + eps assert np . min ( scores ) > 0 # largest scores -> 0 weight # zero score -> inf weight mx = np . max ( scores ) weights = 1 / scores + ( - 3 * mx * mx + 3 * mx * scores - scores * scores ) / ( mx ** 3 ) weights = weights * 2 ** ( ripple_depth * ( 1 + np . cos ( np . pi * scores / mx ) * np . sin ( scores * np . pi * ripple )) ) weights = weights + eps weights = weights / weights . sum () result = ( np . moveaxis ( targets , 0 , - 1 ) * weights ) . sum ( - 1 ) return result Smooth Bases: Interpolate non-discontinuous (for k > 2) tries to prevent discontinuities while preserving the input-output mapping exactly where close to data points. works well with larger k. out-of-domain input areas tend to be averages of many outputs. Source code in src/anguilla/interpolate.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 class Smooth ( Interpolate ): \"\"\"non-discontinuous (for k > 2) tries to prevent discontinuities while preserving the input-output mapping exactly where close to data points. works well with larger k. out-of-domain input areas tend to be averages of many outputs. \"\"\" def __init__ ( self ): super () . __init__ () def __call__ ( self , targets , scores , eps = 1e-9 ): #, smooth=False): targets , scores = np_coerce ( targets , scores ) scores = scores + eps assert np . min ( scores ) > 0 # largest scores -> 0 weight # zero score -> inf weight # zero first/second derivative at largest score mx = np . max ( scores ) weights = 1 / scores + ( - 3 * mx * mx + 3 * mx * scores - scores * scores ) / ( mx ** 3 ) weights = weights + eps weights = weights / weights . sum () result = ( np . moveaxis ( targets , 0 , - 1 ) * weights ) . sum ( - 1 ) return result Softmax Bases: Interpolate mean weighted toward the nearest neighbors. when k is small, has discontinuities when temp is large, tends to average out nearby points -> tends to get 'washed out' for larger k / larger temp when temp is small, acts more like voronoi cells Source code in src/anguilla/interpolate.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 class Softmax ( Interpolate ): \"\"\"mean weighted toward the nearest neighbors. when k is small, has discontinuities when temp is large, tends to average out nearby points -> tends to get 'washed out' for larger k / larger temp when temp is small, acts more like voronoi cells \"\"\" def __init__ ( self ): super () . __init__ () def __call__ ( self , targets , scores , temp = 0.5 ): \"\"\" Args: targets: size [K x ...output_dims...] list or ndarray scores: size [K] list or ndarray \"\"\" targets , scores = np_coerce ( targets , scores ) # print(targets.shape, scores.shape) if temp == 0 : result = targets [ np . argmin ( scores )] else : centered = scores - np . mean ( scores ) # for numerical precision logits = np . maximum ( - centered / temp , - 20 ) # print(f'{logits=}') if np . max ( np . abs ( logits )) > 80 : result = targets [ np . argmin ( scores )] else : weights = np . exp ( logits ) # print(f'{weights=}') weights /= weights . sum () # print(f'{weights=}') result = ( np . moveaxis ( targets , 0 , - 1 ) * weights ) . sum ( - 1 ) # print(f'{result=}') return result __call__ ( targets , scores , temp = 0.5 ) Parameters: Name Type Description Default targets size [K x ...output_dims...] list or ndarray required scores size [K] list or ndarray required Source code in src/anguilla/interpolate.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def __call__ ( self , targets , scores , temp = 0.5 ): \"\"\" Args: targets: size [K x ...output_dims...] list or ndarray scores: size [K] list or ndarray \"\"\" targets , scores = np_coerce ( targets , scores ) # print(targets.shape, scores.shape) if temp == 0 : result = targets [ np . argmin ( scores )] else : centered = scores - np . mean ( scores ) # for numerical precision logits = np . maximum ( - centered / temp , - 20 ) # print(f'{logits=}') if np . max ( np . abs ( logits )) > 80 : result = targets [ np . argmin ( scores )] else : weights = np . exp ( logits ) # print(f'{weights=}') weights /= weights . sum () # print(f'{weights=}') result = ( np . moveaxis ( targets , 0 , - 1 ) * weights ) . sum ( - 1 ) # print(f'{result=}') return result","title":"Interpolate"},{"location":"reference/anguilla/interpolate/#anguilla.interpolate.Interpolate","text":"Bases: JSONSerializable Interpolate combines a set of Outputs weighted by similarity scores. Source code in src/anguilla/interpolate.py 6 7 8 9 10 11 12 13 14 class Interpolate ( JSONSerializable ): \"\"\" Interpolate combines a set of Outputs weighted by similarity scores. \"\"\" def __init__ ( self , ** kw ): super () . __init__ ( ** kw ) def __call__ ( self , targets : List [ Output ], scores : Scores ) -> Output : raise NotImplementedError","title":"Interpolate"},{"location":"reference/anguilla/interpolate/#anguilla.interpolate.Mean","text":"Bases: Interpolate mean of neighbors (piecewise constant mapping) Source code in src/anguilla/interpolate.py 16 17 18 19 20 21 22 class Mean ( Interpolate ): \"\"\"mean of neighbors (piecewise constant mapping)\"\"\" def __init__ ( self ): super () . __init__ () def __call__ ( self , targets , scores ): return sum ( targets ) / len ( targets )","title":"Mean"},{"location":"reference/anguilla/interpolate/#anguilla.interpolate.Ripple","text":"Bases: Interpolate like Smooth but with high-frequency ripples outside the input domain. works well for making random mappings in high dimensional spaces / bootstrapping expressive mappings from a few points. Source code in src/anguilla/interpolate.py 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 class Ripple ( Interpolate ): \"\"\"like Smooth but with high-frequency ripples outside the input domain. works well for making random mappings in high dimensional spaces / bootstrapping expressive mappings from a few points. \"\"\" def __init__ ( self ): super () . __init__ () def __call__ ( self , targets , scores , ripple = 1 , ripple_depth = 1 , eps = 1e-9 ): targets , scores = np_coerce ( targets , scores ) scores = scores + eps assert np . min ( scores ) > 0 # largest scores -> 0 weight # zero score -> inf weight mx = np . max ( scores ) weights = 1 / scores + ( - 3 * mx * mx + 3 * mx * scores - scores * scores ) / ( mx ** 3 ) weights = weights * 2 ** ( ripple_depth * ( 1 + np . cos ( np . pi * scores / mx ) * np . sin ( scores * np . pi * ripple )) ) weights = weights + eps weights = weights / weights . sum () result = ( np . moveaxis ( targets , 0 , - 1 ) * weights ) . sum ( - 1 ) return result","title":"Ripple"},{"location":"reference/anguilla/interpolate/#anguilla.interpolate.Smooth","text":"Bases: Interpolate non-discontinuous (for k > 2) tries to prevent discontinuities while preserving the input-output mapping exactly where close to data points. works well with larger k. out-of-domain input areas tend to be averages of many outputs. Source code in src/anguilla/interpolate.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 class Smooth ( Interpolate ): \"\"\"non-discontinuous (for k > 2) tries to prevent discontinuities while preserving the input-output mapping exactly where close to data points. works well with larger k. out-of-domain input areas tend to be averages of many outputs. \"\"\" def __init__ ( self ): super () . __init__ () def __call__ ( self , targets , scores , eps = 1e-9 ): #, smooth=False): targets , scores = np_coerce ( targets , scores ) scores = scores + eps assert np . min ( scores ) > 0 # largest scores -> 0 weight # zero score -> inf weight # zero first/second derivative at largest score mx = np . max ( scores ) weights = 1 / scores + ( - 3 * mx * mx + 3 * mx * scores - scores * scores ) / ( mx ** 3 ) weights = weights + eps weights = weights / weights . sum () result = ( np . moveaxis ( targets , 0 , - 1 ) * weights ) . sum ( - 1 ) return result","title":"Smooth"},{"location":"reference/anguilla/interpolate/#anguilla.interpolate.Softmax","text":"Bases: Interpolate mean weighted toward the nearest neighbors. when k is small, has discontinuities when temp is large, tends to average out nearby points -> tends to get 'washed out' for larger k / larger temp when temp is small, acts more like voronoi cells Source code in src/anguilla/interpolate.py 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 class Softmax ( Interpolate ): \"\"\"mean weighted toward the nearest neighbors. when k is small, has discontinuities when temp is large, tends to average out nearby points -> tends to get 'washed out' for larger k / larger temp when temp is small, acts more like voronoi cells \"\"\" def __init__ ( self ): super () . __init__ () def __call__ ( self , targets , scores , temp = 0.5 ): \"\"\" Args: targets: size [K x ...output_dims...] list or ndarray scores: size [K] list or ndarray \"\"\" targets , scores = np_coerce ( targets , scores ) # print(targets.shape, scores.shape) if temp == 0 : result = targets [ np . argmin ( scores )] else : centered = scores - np . mean ( scores ) # for numerical precision logits = np . maximum ( - centered / temp , - 20 ) # print(f'{logits=}') if np . max ( np . abs ( logits )) > 80 : result = targets [ np . argmin ( scores )] else : weights = np . exp ( logits ) # print(f'{weights=}') weights /= weights . sum () # print(f'{weights=}') result = ( np . moveaxis ( targets , 0 , - 1 ) * weights ) . sum ( - 1 ) # print(f'{result=}') return result","title":"Softmax"},{"location":"reference/anguilla/interpolate/#anguilla.interpolate.Softmax.__call__","text":"Parameters: Name Type Description Default targets size [K x ...output_dims...] list or ndarray required scores size [K] list or ndarray required Source code in src/anguilla/interpolate.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 def __call__ ( self , targets , scores , temp = 0.5 ): \"\"\" Args: targets: size [K x ...output_dims...] list or ndarray scores: size [K] list or ndarray \"\"\" targets , scores = np_coerce ( targets , scores ) # print(targets.shape, scores.shape) if temp == 0 : result = targets [ np . argmin ( scores )] else : centered = scores - np . mean ( scores ) # for numerical precision logits = np . maximum ( - centered / temp , - 20 ) # print(f'{logits=}') if np . max ( np . abs ( logits )) > 80 : result = targets [ np . argmin ( scores )] else : weights = np . exp ( logits ) # print(f'{weights=}') weights /= weights . sum () # print(f'{weights=}') result = ( np . moveaxis ( targets , 0 , - 1 ) * weights ) . sum ( - 1 ) # print(f'{result=}') return result","title":"__call__()"},{"location":"reference/anguilla/nnsearch/","text":"Index Bases: JSONSerializable base Index class. currently no function besides typing, warning of unimplemented features Source code in src/anguilla/nnsearch.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class Index ( JSONSerializable ): \"\"\"base Index class. currently no function besides typing, warning of unimplemented features \"\"\" def add ( self , feature : Feature , id : Optional [ PairID ] = None ): raise NotImplementedError def remove ( self , id : PairID ): raise NotImplementedError def get ( self , id : PairID ): raise NotImplementedError def search ( self , feature : Feature , k : int ) -> Tuple [ Scores , PairIDs ]: raise NotImplementedError def reset ( self ): raise NotImplementedError @property def ids ( self ): raise NotImplementedError IndexBrute Bases: Index Optimized for simplicity and flexibility, may not scale to large datasets Source code in src/anguilla/nnsearch.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 class IndexBrute ( Index ): \"\"\" Optimized for simplicity and flexibility, may not scale to large datasets \"\"\" def __init__ ( self , d : int = None , metric : Callable = None ): \"\"\" Args: d: optional, dimension of feature metric: distance metric, default to squared euclidean \"\"\" if metric is None : metric = sqL2 () super () . __init__ ( d = d , metric = metric ) self . d = d self . metric = metric self . reset () def add ( self , feature : Feature , id : Optional [ PairID ] = None ) -> PairID : \"\"\"add a new feature, return its ID. Args: feature: the feature to add id: if not supplied, generate a new ID; otherwise, use the supplied id. supply an existing id to replace. \"\"\" if id is None : id = max ( self . data , default =- 1 ) + 1 self . data [ id ] = feature return id def remove ( self , id : PairID ): \"\"\"remove a feature by ID\"\"\" del self . data [ id ] def get ( self , id : PairID ) -> Feature : \"\"\"get a feature by ID\"\"\" return self . data [ id ] def search ( self , feature : Feature , k : int = 3 ) -> Tuple [ PairIDs , Scores ]: \"\"\"get feature(s) and IDs by proximity\"\"\" if not len ( self . data ): return [], [] dist_id = sorted (( self . metric ( feature , v ), k ) for k , v in self . data . items ()) scores , ids = zip ( * dist_id [: k ]) return ids , scores def reset ( self ): self . data : Dict [ PairID , Feature ] = {} @property def ids ( self ): return self . data . keys () __init__ ( d = None , metric = None ) Parameters: Name Type Description Default d int optional, dimension of feature None metric Callable distance metric, default to squared euclidean None Source code in src/anguilla/nnsearch.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , d : int = None , metric : Callable = None ): \"\"\" Args: d: optional, dimension of feature metric: distance metric, default to squared euclidean \"\"\" if metric is None : metric = sqL2 () super () . __init__ ( d = d , metric = metric ) self . d = d self . metric = metric self . reset () add ( feature , id = None ) add a new feature, return its ID. Args: feature: the feature to add id: if not supplied, generate a new ID; otherwise, use the supplied id. supply an existing id to replace. Source code in src/anguilla/nnsearch.py 51 52 53 54 55 56 57 58 59 60 61 62 def add ( self , feature : Feature , id : Optional [ PairID ] = None ) -> PairID : \"\"\"add a new feature, return its ID. Args: feature: the feature to add id: if not supplied, generate a new ID; otherwise, use the supplied id. supply an existing id to replace. \"\"\" if id is None : id = max ( self . data , default =- 1 ) + 1 self . data [ id ] = feature return id get ( id ) get a feature by ID Source code in src/anguilla/nnsearch.py 68 69 70 def get ( self , id : PairID ) -> Feature : \"\"\"get a feature by ID\"\"\" return self . data [ id ] remove ( id ) remove a feature by ID Source code in src/anguilla/nnsearch.py 64 65 66 def remove ( self , id : PairID ): \"\"\"remove a feature by ID\"\"\" del self . data [ id ] search ( feature , k = 3 ) get feature(s) and IDs by proximity Source code in src/anguilla/nnsearch.py 72 73 74 75 76 77 78 def search ( self , feature : Feature , k : int = 3 ) -> Tuple [ PairIDs , Scores ]: \"\"\"get feature(s) and IDs by proximity\"\"\" if not len ( self . data ): return [], [] dist_id = sorted (( self . metric ( feature , v ), k ) for k , v in self . data . items ()) scores , ids = zip ( * dist_id [: k ]) return ids , scores IndexFast Bases: Index Optimized for fast search on large vectors / datasets. Only L2 distance supported. remove may be slow. This is currently a wrapper around faiss.FlatIndexL2 which provides stable ids when using remove In the future could support dot product and/or approximate search indices. Source code in src/anguilla/nnsearch.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 class IndexFast ( Index ): \"\"\" Optimized for fast `search` on large vectors / datasets. Only L2 distance supported. `remove` may be slow. This is currently a wrapper around faiss.FlatIndexL2 which provides stable ids when using `remove` In the future could support dot product and/or approximate search indices. \"\"\" def __init__ ( self , d : int , metric : Callable = sqL2 ): \"\"\" Args: d: dimension of feature metric: \"\"\" super () . __init__ ( d = d , metric = metric ) if metric == sqL2 : self . index = IndexFlatL2 ( d ) else : raise ValueError ( \"\"\"IndexFast supports only sqL2 metric\"\"\" ) self . metric = metric self . reset () @property def d ( self ): return self . index . d def add ( self , feature : Feature , id : Optional [ PairID ] = None ): \"\"\"add a new feature, return its ID. Args: feature: the feature to add id: if not supplied, generate a new ID; otherwise, use the supplied id. supply an existing id to replace. \"\"\" if id is None : # no id supplied case id = max ( self . id_to_idx , default =- 1 ) + 1 elif id in self . id_to_idx : # existing id supplied case self . remove ( id ) feature = feature [ None ] . astype ( np . float32 ) self . index . add ( feature ) idx = self . index . ntotal - 1 # map ID to faiss index self . id_to_idx [ id ] = idx self . idx_to_id [ idx ] = id return id def remove ( self , id : PairID ): \"\"\"remove a feature by ID\"\"\" idx = self . id_to_idx [ id ] self . index . remove_ids ( np . array ( idx )[ None ]) del self . id_to_idx [ id ] del self . idx_to_id [ idx ] # faiss shifts its internal index to stay dense self . id_to_idx = { k :( v - 1 if v > idx else v ) for k , v in self . id_to_idx . items ()} self . idx_to_id = { ( k - 1 if k > idx else k ): v for k , v in self . idx_to_id . items ()} def get ( self , id : PairID ): \"\"\"get a feature by ID\"\"\" idx = self . id_to_idx [ id ] return self . index . reconstruct ( idx ) def search ( self , feature : Feature , k : int = 3 ) -> Tuple [ PairIDs , Scores ]: \"\"\"get feature(s) and IDs by proximity\"\"\" feature = feature [ None ] . astype ( np . float32 ) scores , idxs = self . index . search ( feature , k ) # remove batch dim scores , idxs = scores [ 0 ], idxs [ 0 ] # remove -1 ids b = [ i >= 0 for i in idxs ] scores , idxs = scores [ b ], idxs [ b ] # map back to ids ids = [ self . idx_to_id [ i ] for i in idxs ] return ids , scores def reset ( self ): self . index . reset () self . idx_to_id : Dict [ int , PairID ] = {} self . id_to_idx : Dict [ PairID , int ] = {} @property def ids ( self ): return self . id_to_idx . keys () __init__ ( d , metric = sqL2 ) Parameters: Name Type Description Default d int dimension of feature required metric Callable sqL2 Source code in src/anguilla/nnsearch.py 99 100 101 102 103 104 105 106 107 108 109 110 111 def __init__ ( self , d : int , metric : Callable = sqL2 ): \"\"\" Args: d: dimension of feature metric: \"\"\" super () . __init__ ( d = d , metric = metric ) if metric == sqL2 : self . index = IndexFlatL2 ( d ) else : raise ValueError ( \"\"\"IndexFast supports only sqL2 metric\"\"\" ) self . metric = metric self . reset () add ( feature , id = None ) add a new feature, return its ID. Args: feature: the feature to add id: if not supplied, generate a new ID; otherwise, use the supplied id. supply an existing id to replace. Source code in src/anguilla/nnsearch.py 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 def add ( self , feature : Feature , id : Optional [ PairID ] = None ): \"\"\"add a new feature, return its ID. Args: feature: the feature to add id: if not supplied, generate a new ID; otherwise, use the supplied id. supply an existing id to replace. \"\"\" if id is None : # no id supplied case id = max ( self . id_to_idx , default =- 1 ) + 1 elif id in self . id_to_idx : # existing id supplied case self . remove ( id ) feature = feature [ None ] . astype ( np . float32 ) self . index . add ( feature ) idx = self . index . ntotal - 1 # map ID to faiss index self . id_to_idx [ id ] = idx self . idx_to_id [ idx ] = id return id get ( id ) get a feature by ID Source code in src/anguilla/nnsearch.py 151 152 153 154 def get ( self , id : PairID ): \"\"\"get a feature by ID\"\"\" idx = self . id_to_idx [ id ] return self . index . reconstruct ( idx ) remove ( id ) remove a feature by ID Source code in src/anguilla/nnsearch.py 139 140 141 142 143 144 145 146 147 148 149 def remove ( self , id : PairID ): \"\"\"remove a feature by ID\"\"\" idx = self . id_to_idx [ id ] self . index . remove_ids ( np . array ( idx )[ None ]) del self . id_to_idx [ id ] del self . idx_to_id [ idx ] # faiss shifts its internal index to stay dense self . id_to_idx = { k :( v - 1 if v > idx else v ) for k , v in self . id_to_idx . items ()} self . idx_to_id = { ( k - 1 if k > idx else k ): v for k , v in self . idx_to_id . items ()} search ( feature , k = 3 ) get feature(s) and IDs by proximity Source code in src/anguilla/nnsearch.py 156 157 158 159 160 161 162 163 164 165 166 167 def search ( self , feature : Feature , k : int = 3 ) -> Tuple [ PairIDs , Scores ]: \"\"\"get feature(s) and IDs by proximity\"\"\" feature = feature [ None ] . astype ( np . float32 ) scores , idxs = self . index . search ( feature , k ) # remove batch dim scores , idxs = scores [ 0 ], idxs [ 0 ] # remove -1 ids b = [ i >= 0 for i in idxs ] scores , idxs = scores [ b ], idxs [ b ] # map back to ids ids = [ self . idx_to_id [ i ] for i in idxs ] return ids , scores NNSearch Bases: JSONSerializable This class is the mid-level interface for neighbor search, providing some common utilities over the Index subclasses. Users will generally use IML.search instead of calling NNSearch directly. possibly get rid of this class and fold it into IML? currently adds only complexity to the IML implementation but could be useful if needing NNSearch without Feature/Interpolate? Source code in src/anguilla/nnsearch.py 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 class NNSearch ( JSONSerializable ): \"\"\" This class is the mid-level interface for neighbor search, providing some common utilities over the Index subclasses. Users will generally use `IML.search` instead of calling NNSearch directly. TODO: possibly get rid of this class and fold it into IML? * currently adds only complexity to the IML implementation * but could be useful if needing NNSearch without Feature/Interpolate? \"\"\" def __init__ ( self , index : Index , k = 10 ): \"\"\" Args: index: instance of Index k: default k-nearest neighbors (but can be overridden later) \"\"\" super () . __init__ ( index = index , k = k ) self . index = index self . default_k = k def __call__ ( self , feature : Feature , k : int = None ) -> Tuple [ PairIDs , Scores ]: \"\"\" find the k-nearest neighbors of `feature` Args: feature: query feature vector k: maximum number of neighbors to return Returns: ids: ids of neighbors scores: similarity scores of neighbors (higher is more similar) \"\"\" k = k or self . default_k return self . index . search ( feature , k ) def distance ( self , a : Feature , b : Feature ): \"\"\"compute distance between two features\"\"\" return self . index . metric ( a , b ) def add ( self , feature : Feature , id : Optional [ PairID ] = None ) -> PairID : \"\"\"add a feature vector to the index and return its ID\"\"\" return self . index . add ( feature , id ) def get ( self , id : PairID ) -> Feature : \"\"\"look up a feature by ID\"\"\" try : return self . index . get ( id ) except Exception : print ( f \"NNSearch: WARNING: can't `get` ID { id } which doesn't exist or has been removed\" ) def remove ( self , ids : Union [ PairID , PairIDs ]): \"\"\" Remove point(s) from the index by ID \"\"\" # iterable of ids case: if hasattr ( ids , '__len__' ): for id in ids : self . remove ( id ) # single id case: else : try : self . index . remove ( ids ) except Exception : print ( f \"NNSearch: WARNING: can't `remove` ID { ids } which doesn't exist or has already been removed\" ) def remove_near ( self , feature : Feature , k : int = None ) -> PairIDs : \"\"\" Remove point(s) from the index by proximity. Use k=1 to remove a single point. \"\"\" k = k or self . default_k ids , _ = self ( feature , k = k ) self . remove ( ids ) return ids def reset ( self ): \"\"\"clear all data from the index\"\"\" self . index . reset () def __iter__ ( self ): \"\"\"iterate over IDs in the index\"\"\" return iter ( self . index . ids ) def items ( self ) -> Generator [ IDFeaturePair , None , None ]: \"\"\"iterate over ID, Feature pairs\"\"\" def iterator (): for id in self . index . ids : yield IDFeaturePair ( id , self . index . get ( id )) return iterator () __call__ ( feature , k = None ) find the k-nearest neighbors of feature Args: feature: query feature vector k: maximum number of neighbors to return Returns: ids: ids of neighbors scores: similarity scores of neighbors (higher is more similar) Source code in src/anguilla/nnsearch.py 203 204 205 206 207 208 209 210 211 212 213 214 def __call__ ( self , feature : Feature , k : int = None ) -> Tuple [ PairIDs , Scores ]: \"\"\" find the k-nearest neighbors of `feature` Args: feature: query feature vector k: maximum number of neighbors to return Returns: ids: ids of neighbors scores: similarity scores of neighbors (higher is more similar) \"\"\" k = k or self . default_k return self . index . search ( feature , k ) __init__ ( index , k = 10 ) Parameters: Name Type Description Default index Index instance of Index required k default k-nearest neighbors (but can be overridden later) 10 Source code in src/anguilla/nnsearch.py 193 194 195 196 197 198 199 200 201 def __init__ ( self , index : Index , k = 10 ): \"\"\" Args: index: instance of Index k: default k-nearest neighbors (but can be overridden later) \"\"\" super () . __init__ ( index = index , k = k ) self . index = index self . default_k = k __iter__ () iterate over IDs in the index Source code in src/anguilla/nnsearch.py 260 261 262 def __iter__ ( self ): \"\"\"iterate over IDs in the index\"\"\" return iter ( self . index . ids ) add ( feature , id = None ) add a feature vector to the index and return its ID Source code in src/anguilla/nnsearch.py 220 221 222 def add ( self , feature : Feature , id : Optional [ PairID ] = None ) -> PairID : \"\"\"add a feature vector to the index and return its ID\"\"\" return self . index . add ( feature , id ) distance ( a , b ) compute distance between two features Source code in src/anguilla/nnsearch.py 216 217 218 def distance ( self , a : Feature , b : Feature ): \"\"\"compute distance between two features\"\"\" return self . index . metric ( a , b ) get ( id ) look up a feature by ID Source code in src/anguilla/nnsearch.py 224 225 226 227 228 229 def get ( self , id : PairID ) -> Feature : \"\"\"look up a feature by ID\"\"\" try : return self . index . get ( id ) except Exception : print ( f \"NNSearch: WARNING: can't `get` ID { id } which doesn't exist or has been removed\" ) items () iterate over ID, Feature pairs Source code in src/anguilla/nnsearch.py 264 265 266 267 268 269 def items ( self ) -> Generator [ IDFeaturePair , None , None ]: \"\"\"iterate over ID, Feature pairs\"\"\" def iterator (): for id in self . index . ids : yield IDFeaturePair ( id , self . index . get ( id )) return iterator () remove ( ids ) Remove point(s) from the index by ID Source code in src/anguilla/nnsearch.py 231 232 233 234 235 236 237 238 239 240 241 242 243 244 def remove ( self , ids : Union [ PairID , PairIDs ]): \"\"\" Remove point(s) from the index by ID \"\"\" # iterable of ids case: if hasattr ( ids , '__len__' ): for id in ids : self . remove ( id ) # single id case: else : try : self . index . remove ( ids ) except Exception : print ( f \"NNSearch: WARNING: can't `remove` ID { ids } which doesn't exist or has already been removed\" ) remove_near ( feature , k = None ) Remove point(s) from the index by proximity. Use k=1 to remove a single point. Source code in src/anguilla/nnsearch.py 246 247 248 249 250 251 252 253 254 def remove_near ( self , feature : Feature , k : int = None ) -> PairIDs : \"\"\" Remove point(s) from the index by proximity. Use k=1 to remove a single point. \"\"\" k = k or self . default_k ids , _ = self ( feature , k = k ) self . remove ( ids ) return ids reset () clear all data from the index Source code in src/anguilla/nnsearch.py 256 257 258 def reset ( self ): \"\"\"clear all data from the index\"\"\" self . index . reset ()","title":"Nnsearch"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.Index","text":"Bases: JSONSerializable base Index class. currently no function besides typing, warning of unimplemented features Source code in src/anguilla/nnsearch.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class Index ( JSONSerializable ): \"\"\"base Index class. currently no function besides typing, warning of unimplemented features \"\"\" def add ( self , feature : Feature , id : Optional [ PairID ] = None ): raise NotImplementedError def remove ( self , id : PairID ): raise NotImplementedError def get ( self , id : PairID ): raise NotImplementedError def search ( self , feature : Feature , k : int ) -> Tuple [ Scores , PairIDs ]: raise NotImplementedError def reset ( self ): raise NotImplementedError @property def ids ( self ): raise NotImplementedError","title":"Index"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.IndexBrute","text":"Bases: Index Optimized for simplicity and flexibility, may not scale to large datasets Source code in src/anguilla/nnsearch.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 class IndexBrute ( Index ): \"\"\" Optimized for simplicity and flexibility, may not scale to large datasets \"\"\" def __init__ ( self , d : int = None , metric : Callable = None ): \"\"\" Args: d: optional, dimension of feature metric: distance metric, default to squared euclidean \"\"\" if metric is None : metric = sqL2 () super () . __init__ ( d = d , metric = metric ) self . d = d self . metric = metric self . reset () def add ( self , feature : Feature , id : Optional [ PairID ] = None ) -> PairID : \"\"\"add a new feature, return its ID. Args: feature: the feature to add id: if not supplied, generate a new ID; otherwise, use the supplied id. supply an existing id to replace. \"\"\" if id is None : id = max ( self . data , default =- 1 ) + 1 self . data [ id ] = feature return id def remove ( self , id : PairID ): \"\"\"remove a feature by ID\"\"\" del self . data [ id ] def get ( self , id : PairID ) -> Feature : \"\"\"get a feature by ID\"\"\" return self . data [ id ] def search ( self , feature : Feature , k : int = 3 ) -> Tuple [ PairIDs , Scores ]: \"\"\"get feature(s) and IDs by proximity\"\"\" if not len ( self . data ): return [], [] dist_id = sorted (( self . metric ( feature , v ), k ) for k , v in self . data . items ()) scores , ids = zip ( * dist_id [: k ]) return ids , scores def reset ( self ): self . data : Dict [ PairID , Feature ] = {} @property def ids ( self ): return self . data . keys ()","title":"IndexBrute"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.IndexBrute.__init__","text":"Parameters: Name Type Description Default d int optional, dimension of feature None metric Callable distance metric, default to squared euclidean None Source code in src/anguilla/nnsearch.py 36 37 38 39 40 41 42 43 44 45 46 47 48 49 def __init__ ( self , d : int = None , metric : Callable = None ): \"\"\" Args: d: optional, dimension of feature metric: distance metric, default to squared euclidean \"\"\" if metric is None : metric = sqL2 () super () . __init__ ( d = d , metric = metric ) self . d = d self . metric = metric self . reset ()","title":"__init__()"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.IndexBrute.add","text":"add a new feature, return its ID. Args: feature: the feature to add id: if not supplied, generate a new ID; otherwise, use the supplied id. supply an existing id to replace. Source code in src/anguilla/nnsearch.py 51 52 53 54 55 56 57 58 59 60 61 62 def add ( self , feature : Feature , id : Optional [ PairID ] = None ) -> PairID : \"\"\"add a new feature, return its ID. Args: feature: the feature to add id: if not supplied, generate a new ID; otherwise, use the supplied id. supply an existing id to replace. \"\"\" if id is None : id = max ( self . data , default =- 1 ) + 1 self . data [ id ] = feature return id","title":"add()"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.IndexBrute.get","text":"get a feature by ID Source code in src/anguilla/nnsearch.py 68 69 70 def get ( self , id : PairID ) -> Feature : \"\"\"get a feature by ID\"\"\" return self . data [ id ]","title":"get()"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.IndexBrute.remove","text":"remove a feature by ID Source code in src/anguilla/nnsearch.py 64 65 66 def remove ( self , id : PairID ): \"\"\"remove a feature by ID\"\"\" del self . data [ id ]","title":"remove()"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.IndexBrute.search","text":"get feature(s) and IDs by proximity Source code in src/anguilla/nnsearch.py 72 73 74 75 76 77 78 def search ( self , feature : Feature , k : int = 3 ) -> Tuple [ PairIDs , Scores ]: \"\"\"get feature(s) and IDs by proximity\"\"\" if not len ( self . data ): return [], [] dist_id = sorted (( self . metric ( feature , v ), k ) for k , v in self . data . items ()) scores , ids = zip ( * dist_id [: k ]) return ids , scores","title":"search()"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.IndexFast","text":"Bases: Index Optimized for fast search on large vectors / datasets. Only L2 distance supported. remove may be slow. This is currently a wrapper around faiss.FlatIndexL2 which provides stable ids when using remove In the future could support dot product and/or approximate search indices. Source code in src/anguilla/nnsearch.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 class IndexFast ( Index ): \"\"\" Optimized for fast `search` on large vectors / datasets. Only L2 distance supported. `remove` may be slow. This is currently a wrapper around faiss.FlatIndexL2 which provides stable ids when using `remove` In the future could support dot product and/or approximate search indices. \"\"\" def __init__ ( self , d : int , metric : Callable = sqL2 ): \"\"\" Args: d: dimension of feature metric: \"\"\" super () . __init__ ( d = d , metric = metric ) if metric == sqL2 : self . index = IndexFlatL2 ( d ) else : raise ValueError ( \"\"\"IndexFast supports only sqL2 metric\"\"\" ) self . metric = metric self . reset () @property def d ( self ): return self . index . d def add ( self , feature : Feature , id : Optional [ PairID ] = None ): \"\"\"add a new feature, return its ID. Args: feature: the feature to add id: if not supplied, generate a new ID; otherwise, use the supplied id. supply an existing id to replace. \"\"\" if id is None : # no id supplied case id = max ( self . id_to_idx , default =- 1 ) + 1 elif id in self . id_to_idx : # existing id supplied case self . remove ( id ) feature = feature [ None ] . astype ( np . float32 ) self . index . add ( feature ) idx = self . index . ntotal - 1 # map ID to faiss index self . id_to_idx [ id ] = idx self . idx_to_id [ idx ] = id return id def remove ( self , id : PairID ): \"\"\"remove a feature by ID\"\"\" idx = self . id_to_idx [ id ] self . index . remove_ids ( np . array ( idx )[ None ]) del self . id_to_idx [ id ] del self . idx_to_id [ idx ] # faiss shifts its internal index to stay dense self . id_to_idx = { k :( v - 1 if v > idx else v ) for k , v in self . id_to_idx . items ()} self . idx_to_id = { ( k - 1 if k > idx else k ): v for k , v in self . idx_to_id . items ()} def get ( self , id : PairID ): \"\"\"get a feature by ID\"\"\" idx = self . id_to_idx [ id ] return self . index . reconstruct ( idx ) def search ( self , feature : Feature , k : int = 3 ) -> Tuple [ PairIDs , Scores ]: \"\"\"get feature(s) and IDs by proximity\"\"\" feature = feature [ None ] . astype ( np . float32 ) scores , idxs = self . index . search ( feature , k ) # remove batch dim scores , idxs = scores [ 0 ], idxs [ 0 ] # remove -1 ids b = [ i >= 0 for i in idxs ] scores , idxs = scores [ b ], idxs [ b ] # map back to ids ids = [ self . idx_to_id [ i ] for i in idxs ] return ids , scores def reset ( self ): self . index . reset () self . idx_to_id : Dict [ int , PairID ] = {} self . id_to_idx : Dict [ PairID , int ] = {} @property def ids ( self ): return self . id_to_idx . keys ()","title":"IndexFast"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.IndexFast.__init__","text":"Parameters: Name Type Description Default d int dimension of feature required metric Callable sqL2 Source code in src/anguilla/nnsearch.py 99 100 101 102 103 104 105 106 107 108 109 110 111 def __init__ ( self , d : int , metric : Callable = sqL2 ): \"\"\" Args: d: dimension of feature metric: \"\"\" super () . __init__ ( d = d , metric = metric ) if metric == sqL2 : self . index = IndexFlatL2 ( d ) else : raise ValueError ( \"\"\"IndexFast supports only sqL2 metric\"\"\" ) self . metric = metric self . reset ()","title":"__init__()"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.IndexFast.add","text":"add a new feature, return its ID. Args: feature: the feature to add id: if not supplied, generate a new ID; otherwise, use the supplied id. supply an existing id to replace. Source code in src/anguilla/nnsearch.py 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 def add ( self , feature : Feature , id : Optional [ PairID ] = None ): \"\"\"add a new feature, return its ID. Args: feature: the feature to add id: if not supplied, generate a new ID; otherwise, use the supplied id. supply an existing id to replace. \"\"\" if id is None : # no id supplied case id = max ( self . id_to_idx , default =- 1 ) + 1 elif id in self . id_to_idx : # existing id supplied case self . remove ( id ) feature = feature [ None ] . astype ( np . float32 ) self . index . add ( feature ) idx = self . index . ntotal - 1 # map ID to faiss index self . id_to_idx [ id ] = idx self . idx_to_id [ idx ] = id return id","title":"add()"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.IndexFast.get","text":"get a feature by ID Source code in src/anguilla/nnsearch.py 151 152 153 154 def get ( self , id : PairID ): \"\"\"get a feature by ID\"\"\" idx = self . id_to_idx [ id ] return self . index . reconstruct ( idx )","title":"get()"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.IndexFast.remove","text":"remove a feature by ID Source code in src/anguilla/nnsearch.py 139 140 141 142 143 144 145 146 147 148 149 def remove ( self , id : PairID ): \"\"\"remove a feature by ID\"\"\" idx = self . id_to_idx [ id ] self . index . remove_ids ( np . array ( idx )[ None ]) del self . id_to_idx [ id ] del self . idx_to_id [ idx ] # faiss shifts its internal index to stay dense self . id_to_idx = { k :( v - 1 if v > idx else v ) for k , v in self . id_to_idx . items ()} self . idx_to_id = { ( k - 1 if k > idx else k ): v for k , v in self . idx_to_id . items ()}","title":"remove()"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.IndexFast.search","text":"get feature(s) and IDs by proximity Source code in src/anguilla/nnsearch.py 156 157 158 159 160 161 162 163 164 165 166 167 def search ( self , feature : Feature , k : int = 3 ) -> Tuple [ PairIDs , Scores ]: \"\"\"get feature(s) and IDs by proximity\"\"\" feature = feature [ None ] . astype ( np . float32 ) scores , idxs = self . index . search ( feature , k ) # remove batch dim scores , idxs = scores [ 0 ], idxs [ 0 ] # remove -1 ids b = [ i >= 0 for i in idxs ] scores , idxs = scores [ b ], idxs [ b ] # map back to ids ids = [ self . idx_to_id [ i ] for i in idxs ] return ids , scores","title":"search()"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.NNSearch","text":"Bases: JSONSerializable This class is the mid-level interface for neighbor search, providing some common utilities over the Index subclasses. Users will generally use IML.search instead of calling NNSearch directly. possibly get rid of this class and fold it into IML? currently adds only complexity to the IML implementation but could be useful if needing NNSearch without Feature/Interpolate? Source code in src/anguilla/nnsearch.py 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 class NNSearch ( JSONSerializable ): \"\"\" This class is the mid-level interface for neighbor search, providing some common utilities over the Index subclasses. Users will generally use `IML.search` instead of calling NNSearch directly. TODO: possibly get rid of this class and fold it into IML? * currently adds only complexity to the IML implementation * but could be useful if needing NNSearch without Feature/Interpolate? \"\"\" def __init__ ( self , index : Index , k = 10 ): \"\"\" Args: index: instance of Index k: default k-nearest neighbors (but can be overridden later) \"\"\" super () . __init__ ( index = index , k = k ) self . index = index self . default_k = k def __call__ ( self , feature : Feature , k : int = None ) -> Tuple [ PairIDs , Scores ]: \"\"\" find the k-nearest neighbors of `feature` Args: feature: query feature vector k: maximum number of neighbors to return Returns: ids: ids of neighbors scores: similarity scores of neighbors (higher is more similar) \"\"\" k = k or self . default_k return self . index . search ( feature , k ) def distance ( self , a : Feature , b : Feature ): \"\"\"compute distance between two features\"\"\" return self . index . metric ( a , b ) def add ( self , feature : Feature , id : Optional [ PairID ] = None ) -> PairID : \"\"\"add a feature vector to the index and return its ID\"\"\" return self . index . add ( feature , id ) def get ( self , id : PairID ) -> Feature : \"\"\"look up a feature by ID\"\"\" try : return self . index . get ( id ) except Exception : print ( f \"NNSearch: WARNING: can't `get` ID { id } which doesn't exist or has been removed\" ) def remove ( self , ids : Union [ PairID , PairIDs ]): \"\"\" Remove point(s) from the index by ID \"\"\" # iterable of ids case: if hasattr ( ids , '__len__' ): for id in ids : self . remove ( id ) # single id case: else : try : self . index . remove ( ids ) except Exception : print ( f \"NNSearch: WARNING: can't `remove` ID { ids } which doesn't exist or has already been removed\" ) def remove_near ( self , feature : Feature , k : int = None ) -> PairIDs : \"\"\" Remove point(s) from the index by proximity. Use k=1 to remove a single point. \"\"\" k = k or self . default_k ids , _ = self ( feature , k = k ) self . remove ( ids ) return ids def reset ( self ): \"\"\"clear all data from the index\"\"\" self . index . reset () def __iter__ ( self ): \"\"\"iterate over IDs in the index\"\"\" return iter ( self . index . ids ) def items ( self ) -> Generator [ IDFeaturePair , None , None ]: \"\"\"iterate over ID, Feature pairs\"\"\" def iterator (): for id in self . index . ids : yield IDFeaturePair ( id , self . index . get ( id )) return iterator ()","title":"NNSearch"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.NNSearch.__call__","text":"find the k-nearest neighbors of feature Args: feature: query feature vector k: maximum number of neighbors to return Returns: ids: ids of neighbors scores: similarity scores of neighbors (higher is more similar) Source code in src/anguilla/nnsearch.py 203 204 205 206 207 208 209 210 211 212 213 214 def __call__ ( self , feature : Feature , k : int = None ) -> Tuple [ PairIDs , Scores ]: \"\"\" find the k-nearest neighbors of `feature` Args: feature: query feature vector k: maximum number of neighbors to return Returns: ids: ids of neighbors scores: similarity scores of neighbors (higher is more similar) \"\"\" k = k or self . default_k return self . index . search ( feature , k )","title":"__call__()"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.NNSearch.__init__","text":"Parameters: Name Type Description Default index Index instance of Index required k default k-nearest neighbors (but can be overridden later) 10 Source code in src/anguilla/nnsearch.py 193 194 195 196 197 198 199 200 201 def __init__ ( self , index : Index , k = 10 ): \"\"\" Args: index: instance of Index k: default k-nearest neighbors (but can be overridden later) \"\"\" super () . __init__ ( index = index , k = k ) self . index = index self . default_k = k","title":"__init__()"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.NNSearch.__iter__","text":"iterate over IDs in the index Source code in src/anguilla/nnsearch.py 260 261 262 def __iter__ ( self ): \"\"\"iterate over IDs in the index\"\"\" return iter ( self . index . ids )","title":"__iter__()"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.NNSearch.add","text":"add a feature vector to the index and return its ID Source code in src/anguilla/nnsearch.py 220 221 222 def add ( self , feature : Feature , id : Optional [ PairID ] = None ) -> PairID : \"\"\"add a feature vector to the index and return its ID\"\"\" return self . index . add ( feature , id )","title":"add()"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.NNSearch.distance","text":"compute distance between two features Source code in src/anguilla/nnsearch.py 216 217 218 def distance ( self , a : Feature , b : Feature ): \"\"\"compute distance between two features\"\"\" return self . index . metric ( a , b )","title":"distance()"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.NNSearch.get","text":"look up a feature by ID Source code in src/anguilla/nnsearch.py 224 225 226 227 228 229 def get ( self , id : PairID ) -> Feature : \"\"\"look up a feature by ID\"\"\" try : return self . index . get ( id ) except Exception : print ( f \"NNSearch: WARNING: can't `get` ID { id } which doesn't exist or has been removed\" )","title":"get()"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.NNSearch.items","text":"iterate over ID, Feature pairs Source code in src/anguilla/nnsearch.py 264 265 266 267 268 269 def items ( self ) -> Generator [ IDFeaturePair , None , None ]: \"\"\"iterate over ID, Feature pairs\"\"\" def iterator (): for id in self . index . ids : yield IDFeaturePair ( id , self . index . get ( id )) return iterator ()","title":"items()"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.NNSearch.remove","text":"Remove point(s) from the index by ID Source code in src/anguilla/nnsearch.py 231 232 233 234 235 236 237 238 239 240 241 242 243 244 def remove ( self , ids : Union [ PairID , PairIDs ]): \"\"\" Remove point(s) from the index by ID \"\"\" # iterable of ids case: if hasattr ( ids , '__len__' ): for id in ids : self . remove ( id ) # single id case: else : try : self . index . remove ( ids ) except Exception : print ( f \"NNSearch: WARNING: can't `remove` ID { ids } which doesn't exist or has already been removed\" )","title":"remove()"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.NNSearch.remove_near","text":"Remove point(s) from the index by proximity. Use k=1 to remove a single point. Source code in src/anguilla/nnsearch.py 246 247 248 249 250 251 252 253 254 def remove_near ( self , feature : Feature , k : int = None ) -> PairIDs : \"\"\" Remove point(s) from the index by proximity. Use k=1 to remove a single point. \"\"\" k = k or self . default_k ids , _ = self ( feature , k = k ) self . remove ( ids ) return ids","title":"remove_near()"},{"location":"reference/anguilla/nnsearch/#anguilla.nnsearch.NNSearch.reset","text":"clear all data from the index Source code in src/anguilla/nnsearch.py 256 257 258 def reset ( self ): \"\"\"clear all data from the index\"\"\" self . index . reset ()","title":"reset()"},{"location":"reference/anguilla/serialize/","text":"JSONSerializable JSON serialization for Python classes. Saves keyword arguments at construction, and also any state returned by the save_state method. to make class a serializable, subclass JSONSerializable, and in the constructor use e.g. super().__init__(a=0, b=1 ...) with any keyword args which should be serialized. override save_state and load_state to handle any mutable state. Constructor args and return values of save_state can be other JSONSerializable objects. Source code in src/anguilla/serialize.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 class JSONSerializable : \"\"\"JSON serialization for Python classes. Saves keyword arguments at construction, and also any state returned by the `save_state` method. to make class a serializable, subclass JSONSerializable, and in the constructor use e.g. `super().__init__(a=0, b=1 ...)` with any keyword args which should be serialized. override `save_state` and `load_state` to handle any mutable state. Constructor args and return values of `save_state` can be other JSONSerializable objects. \"\"\" def __init__ ( self , ** kw ): self . _kw = deepcopy ( kw ) self . _kw [ '__inst__' ] = '.' . join (( self . __class__ . __module__ , self . __class__ . __name__ )) def _store ( self ): return { '__state__' : self . save_state (), ** self . _kw } def save_state ( self ): \"\"\"return object state in JSON serializable form\"\"\" return None def load_state ( self , state ): \"\"\"restore from de-serialized state\"\"\" pass load_state ( state ) restore from de-serialized state Source code in src/anguilla/serialize.py 31 32 33 def load_state ( self , state ): \"\"\"restore from de-serialized state\"\"\" pass save_state () return object state in JSON serializable form Source code in src/anguilla/serialize.py 27 28 29 def save_state ( self ): \"\"\"return object state in JSON serializable form\"\"\" return None","title":"Serialize"},{"location":"reference/anguilla/serialize/#anguilla.serialize.JSONSerializable","text":"JSON serialization for Python classes. Saves keyword arguments at construction, and also any state returned by the save_state method. to make class a serializable, subclass JSONSerializable, and in the constructor use e.g. super().__init__(a=0, b=1 ...) with any keyword args which should be serialized. override save_state and load_state to handle any mutable state. Constructor args and return values of save_state can be other JSONSerializable objects. Source code in src/anguilla/serialize.py 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 class JSONSerializable : \"\"\"JSON serialization for Python classes. Saves keyword arguments at construction, and also any state returned by the `save_state` method. to make class a serializable, subclass JSONSerializable, and in the constructor use e.g. `super().__init__(a=0, b=1 ...)` with any keyword args which should be serialized. override `save_state` and `load_state` to handle any mutable state. Constructor args and return values of `save_state` can be other JSONSerializable objects. \"\"\" def __init__ ( self , ** kw ): self . _kw = deepcopy ( kw ) self . _kw [ '__inst__' ] = '.' . join (( self . __class__ . __module__ , self . __class__ . __name__ )) def _store ( self ): return { '__state__' : self . save_state (), ** self . _kw } def save_state ( self ): \"\"\"return object state in JSON serializable form\"\"\" return None def load_state ( self , state ): \"\"\"restore from de-serialized state\"\"\" pass","title":"JSONSerializable"},{"location":"reference/anguilla/serialize/#anguilla.serialize.JSONSerializable.load_state","text":"restore from de-serialized state Source code in src/anguilla/serialize.py 31 32 33 def load_state ( self , state ): \"\"\"restore from de-serialized state\"\"\" pass","title":"load_state()"},{"location":"reference/anguilla/serialize/#anguilla.serialize.JSONSerializable.save_state","text":"return object state in JSON serializable form Source code in src/anguilla/serialize.py 27 28 29 def save_state ( self ): \"\"\"return object state in JSON serializable form\"\"\" return None","title":"save_state()"},{"location":"reference/anguilla/types/","text":"","title":"Types"},{"location":"reference/anguilla/app/__init__/","text":"","title":"  init  "},{"location":"reference/anguilla/app/server/","text":"Authors Victor Shepardson Intelligent Instruments Lab 2023 main ( osc_port = 8732 , osc_return_port = None , osc_host = '' ) Parameters: Name Type Description Default osc_port int listen for OSC controls on this port 8732 osc_return_port Optional [ int ] if supplied, reply on a different port than osc_port None osc_host str leave this as empty string to get all traffic on the port '' OSC Routes: /iml/config/emb \"Identity\" set embedding to Identity (the default) /iml/config/emb \"ProjectAndSort\" set embedding to ProjectAndSort /iml/config/interp \"Smooth\" set interpolator to Smooth (the default) /iml/config/interp \"Softmax\" set interpolator to Softmax /iml/config/interp \"Ripple\" set interpolator to Ripple -- or -- /iml/config \"emb\" ... \"interp\" ... /iml/add \"input\" ... \"output\"... add a point to the mapping /iml/remove id remove a point from the mapping by ID /iml/remove_near \"input\" ... [\"k\" k] remove k points from the mapping by proximity /iml/map \"input\" ... [\"k\" k] [\"ripple\" r] [\"temp\" t] map an input to an output using k neighbors \"temp\" 1 > t > 0 when using Softmax interpolator \"ripple\" r > 0 when using Ripple interpolator /iml/reset remove all points /iml/reset \"keep_near\" ... [\"k\" k] remove all points except the k neighbors of \"keep_near\" /iml/load path load IML from file at `path` /iml/save path save IML to file at `path` Source code in src/anguilla/app/server.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 def main ( osc_port : int = 8732 , osc_return_port : Optional [ int ] = None , osc_host : str = '' , ): \"\"\" Args: osc_port: listen for OSC controls on this port osc_return_port: if supplied, reply on a different port than osc_port osc_host: leave this as empty string to get all traffic on the port OSC Routes: /iml/config/emb \"Identity\" set embedding to Identity (the default) /iml/config/emb \"ProjectAndSort\" set embedding to ProjectAndSort /iml/config/interp \"Smooth\" set interpolator to Smooth (the default) /iml/config/interp \"Softmax\" set interpolator to Softmax /iml/config/interp \"Ripple\" set interpolator to Ripple -- or -- /iml/config \"emb\" ... \"interp\" ... /iml/add \"input\" ... \"output\"... add a point to the mapping /iml/remove id remove a point from the mapping by ID /iml/remove_near \"input\" ... [\"k\" k] remove k points from the mapping by proximity /iml/map \"input\" ... [\"k\" k] [\"ripple\" r] [\"temp\" t] map an input to an output using k neighbors \"temp\" 1 > t > 0 when using Softmax interpolator \"ripple\" r > 0 when using Ripple interpolator /iml/reset remove all points /iml/reset \"keep_near\" ... [\"k\" k] remove all points except the k neighbors of \"keep_near\" /iml/load path load IML from file at `path` /iml/save path save IML to file at `path` \"\"\" osc = OSC ( osc_host , osc_port ) iml = None config = {} @osc . kwargs ( '/iml/config' ) def _ ( address , ** kw ): # TODO: validate input config . update ( kw ) print ( config ) @osc . args ( '/iml/config/interp' ) def _ ( address , name ): if iml is None : config [ 'interp' ] = name else : iml . set_interp ( name ) @osc . args ( '/iml/config/emb' ) def _ ( address , name ): if iml is None : config [ 'emb' ] = name else : iml . set_emb ( name ) @osc . args ( '/iml/add' ) def _ ( address , * a ): nonlocal iml kw = vector_args ( a ) if 'input' not in kw : print ( 'ERROR: iml: no input vector supplied' ) return if 'output' not in kw : print ( 'ERROR: iml: no output vector supplied' ) return # d = len(kw['input']) # config['feature_size'] = d if iml is None : # print(f'new IML object with Input dimension {d}') print ( f 'new IML object with { config } ' ) iml = IML ( ** config ) return '/iml/return/add' , iml . add ( ** kw ) @osc . args ( '/iml/remove' ) def _ ( address , id ): iml . remove ( id ) @osc . args ( '/iml/remove_near' ) def _ ( address , * a ): kw = vector_args ( a ) for k in [ 'k' ]: if k in kw : kw [ k ] = kw [ k ][ 0 ] if 'input' not in kw : print ( 'ERROR: iml: no input vector supplied' ) return iml . remove_near ( ** kw ) @osc . args ( '/iml/map' , return_port = osc_return_port ) def _ ( address , * a ): kw = vector_args ( a ) for k in [ 'k' , 'temp' , 'ripple' ]: if k in kw : kw [ k ] = kw [ k ][ 0 ] if 'input' not in kw : print ( 'ERROR: iml: no input vector supplied' ) return if iml is None : print ( 'ERROR: iml: call /iml/add at least once before /map' ) return result = iml . map ( ** kw ) . tolist () return '/iml/return/map' , * result @osc . args ( '/iml/reset' ) def _ ( address , * a ): if iml is not None : kw = vector_args ( a ) for k in [ 'k' ]: if k in kw : kw [ k ] = kw [ k ][ 0 ] iml . reset ( ** kw ) @osc . args ( '/iml/load' ) def _ ( address , path ): nonlocal iml assert isinstance ( path , str ) assert path . endswith ( '.json' ), \"ERROR: iml: path should end with .json\" print ( f 'new IML object from { path } ' ) iml = IML . load ( path ) @osc . args ( '/iml/save' ) def _ ( address , path ): assert isinstance ( path , str ) assert path . endswith ( '.json' ), \"ERROR: iml: path should end with .json\" print ( f 'saving IML object to { path } ' ) iml . save ( path )","title":"Server"},{"location":"reference/anguilla/app/server/#anguilla.app.server.main","text":"Parameters: Name Type Description Default osc_port int listen for OSC controls on this port 8732 osc_return_port Optional [ int ] if supplied, reply on a different port than osc_port None osc_host str leave this as empty string to get all traffic on the port '' OSC Routes: /iml/config/emb \"Identity\" set embedding to Identity (the default) /iml/config/emb \"ProjectAndSort\" set embedding to ProjectAndSort /iml/config/interp \"Smooth\" set interpolator to Smooth (the default) /iml/config/interp \"Softmax\" set interpolator to Softmax /iml/config/interp \"Ripple\" set interpolator to Ripple -- or -- /iml/config \"emb\" ... \"interp\" ... /iml/add \"input\" ... \"output\"... add a point to the mapping /iml/remove id remove a point from the mapping by ID /iml/remove_near \"input\" ... [\"k\" k] remove k points from the mapping by proximity /iml/map \"input\" ... [\"k\" k] [\"ripple\" r] [\"temp\" t] map an input to an output using k neighbors \"temp\" 1 > t > 0 when using Softmax interpolator \"ripple\" r > 0 when using Ripple interpolator /iml/reset remove all points /iml/reset \"keep_near\" ... [\"k\" k] remove all points except the k neighbors of \"keep_near\" /iml/load path load IML from file at `path` /iml/save path save IML to file at `path` Source code in src/anguilla/app/server.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 def main ( osc_port : int = 8732 , osc_return_port : Optional [ int ] = None , osc_host : str = '' , ): \"\"\" Args: osc_port: listen for OSC controls on this port osc_return_port: if supplied, reply on a different port than osc_port osc_host: leave this as empty string to get all traffic on the port OSC Routes: /iml/config/emb \"Identity\" set embedding to Identity (the default) /iml/config/emb \"ProjectAndSort\" set embedding to ProjectAndSort /iml/config/interp \"Smooth\" set interpolator to Smooth (the default) /iml/config/interp \"Softmax\" set interpolator to Softmax /iml/config/interp \"Ripple\" set interpolator to Ripple -- or -- /iml/config \"emb\" ... \"interp\" ... /iml/add \"input\" ... \"output\"... add a point to the mapping /iml/remove id remove a point from the mapping by ID /iml/remove_near \"input\" ... [\"k\" k] remove k points from the mapping by proximity /iml/map \"input\" ... [\"k\" k] [\"ripple\" r] [\"temp\" t] map an input to an output using k neighbors \"temp\" 1 > t > 0 when using Softmax interpolator \"ripple\" r > 0 when using Ripple interpolator /iml/reset remove all points /iml/reset \"keep_near\" ... [\"k\" k] remove all points except the k neighbors of \"keep_near\" /iml/load path load IML from file at `path` /iml/save path save IML to file at `path` \"\"\" osc = OSC ( osc_host , osc_port ) iml = None config = {} @osc . kwargs ( '/iml/config' ) def _ ( address , ** kw ): # TODO: validate input config . update ( kw ) print ( config ) @osc . args ( '/iml/config/interp' ) def _ ( address , name ): if iml is None : config [ 'interp' ] = name else : iml . set_interp ( name ) @osc . args ( '/iml/config/emb' ) def _ ( address , name ): if iml is None : config [ 'emb' ] = name else : iml . set_emb ( name ) @osc . args ( '/iml/add' ) def _ ( address , * a ): nonlocal iml kw = vector_args ( a ) if 'input' not in kw : print ( 'ERROR: iml: no input vector supplied' ) return if 'output' not in kw : print ( 'ERROR: iml: no output vector supplied' ) return # d = len(kw['input']) # config['feature_size'] = d if iml is None : # print(f'new IML object with Input dimension {d}') print ( f 'new IML object with { config } ' ) iml = IML ( ** config ) return '/iml/return/add' , iml . add ( ** kw ) @osc . args ( '/iml/remove' ) def _ ( address , id ): iml . remove ( id ) @osc . args ( '/iml/remove_near' ) def _ ( address , * a ): kw = vector_args ( a ) for k in [ 'k' ]: if k in kw : kw [ k ] = kw [ k ][ 0 ] if 'input' not in kw : print ( 'ERROR: iml: no input vector supplied' ) return iml . remove_near ( ** kw ) @osc . args ( '/iml/map' , return_port = osc_return_port ) def _ ( address , * a ): kw = vector_args ( a ) for k in [ 'k' , 'temp' , 'ripple' ]: if k in kw : kw [ k ] = kw [ k ][ 0 ] if 'input' not in kw : print ( 'ERROR: iml: no input vector supplied' ) return if iml is None : print ( 'ERROR: iml: call /iml/add at least once before /map' ) return result = iml . map ( ** kw ) . tolist () return '/iml/return/map' , * result @osc . args ( '/iml/reset' ) def _ ( address , * a ): if iml is not None : kw = vector_args ( a ) for k in [ 'k' ]: if k in kw : kw [ k ] = kw [ k ][ 0 ] iml . reset ( ** kw ) @osc . args ( '/iml/load' ) def _ ( address , path ): nonlocal iml assert isinstance ( path , str ) assert path . endswith ( '.json' ), \"ERROR: iml: path should end with .json\" print ( f 'new IML object from { path } ' ) iml = IML . load ( path ) @osc . args ( '/iml/save' ) def _ ( address , path ): assert isinstance ( path , str ) assert path . endswith ( '.json' ), \"ERROR: iml: path should end with .json\" print ( f 'saving IML object to { path } ' ) iml . save ( path )","title":"main()"}]}